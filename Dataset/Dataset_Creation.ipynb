{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "\n",
    "# Classic\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Pytorch \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms, datasets\n",
    "from IPython import display\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Loading the MNIST dataset\n",
    "\n",
    "path = './data/torch_data/VGAN/MNIST/dataset'\n",
    "compose = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((.5, .5, .5), (.5, .5, .5))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root = path, train = True, transform = compose, download = False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = 60000, shuffle = True)\n",
    "test_dataset = datasets.MNIST(root = path, train = False, transform = compose, download = False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,batch_size = 10000, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "## Store the images into the repective train and test variables\n",
    "\n",
    "data_list = [train_loader, test_loader]\n",
    "\n",
    "## Loop through the datasets (train/test)\n",
    "for data in data_list:\n",
    "\n",
    "    for image, labels in data:\n",
    "        \n",
    "        if image.shape[0] == 60000:\n",
    "            temp_idx = np.random.choice(image.shape[0], 50000, replace=False)\n",
    "            train_x = image[temp_idx].detach().numpy()\n",
    "            train_y = labels[temp_idx].detach().numpy()\n",
    "        else:\n",
    "            temp_idx = np.random.choice(image.shape[0], 7500, replace=False)\n",
    "            test_x = image[temp_idx].detach().numpy()\n",
    "            test_y = labels[temp_idx].detach().numpy()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "## Extract 30000 images for mnist and 20000 for autoencoders\n",
    "\n",
    "random_idx = np.random.permutation(50000)\n",
    "# Parsing train data amongst mnist and autoencoders\n",
    "mnist_train_x = train_x[random_idx[:30000]]\n",
    "mnist_train_y = train_y[random_idx[:30000]]\n",
    "ae_train_x = train_x[random_idx[30000:]]\n",
    "ae_train_y = train_y[random_idx[30000:]]\n",
    "\n",
    "\n",
    "## Extract 5000 images for mnist and 2500 for autoencoders\n",
    "\n",
    "random_idx = np.random.permutation(7500)\n",
    "# Parsing test data amongst mnist and autoencoders\n",
    "mnist_test_x = test_x[random_idx[:5000]]\n",
    "mnist_test_y = test_y[random_idx[:5000]]\n",
    "ae_test_x = test_x[random_idx[5000:]]\n",
    "ae_test_y = test_y[random_idx[5000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Save train and test sets for autoencoders\n",
    "np.save(\"data/ae_train_x\", ae_train_x)\n",
    "np.save(\"data/ae_test_x\", ae_test_x)\n",
    "\n",
    "## Load numpy tensors\n",
    "# np.load(\"data/X_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Loading numpy tensors from autoencoders\n",
    "ae_train_x_new = np.load('data/ae_train_x_new.npy')\n",
    "#ae_train_x_new = (ae_train_x_new - 0.5)/0.5\n",
    "ae_test_x_new = np.load('data/ae_test_x_new.npy')\n",
    "#ae_test_x_new = (ae_test_x_new - 0.5)/0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "## Reading and storing images from DC_GAN\n",
    "train_x_gan = np.empty((10000,1,28,28))\n",
    "train_y_gan = np.empty((10000,))\n",
    "test_x_gan = np.empty((2500,1,28,28))\n",
    "test_y_gan = np.empty((2500,))\n",
    "\n",
    "for digit in range(10):\n",
    "    \n",
    "    temp_image = np.load(\"data/{}.npy\".format(digit))\n",
    "    train_y_gan[digit*1000:(digit+1)*1000] = digit\n",
    "    test_y_gan[digit*250:(digit+1)*250] = digit\n",
    "    \n",
    "    for image in range(1250):\n",
    "        \n",
    "        img = cv2.resize(temp_image[image][0], (28, 28)) \n",
    "        img = img.reshape((1,28,28))\n",
    "        if image < 1000:\n",
    "            train_x_gan[digit*1000 + image] = img\n",
    "        else:\n",
    "            test_x_gan[digit*250 + (image-1000)] = img\n",
    "\n",
    "            \n",
    "## Randomize the set\n",
    "\n",
    "# Train\n",
    "idx = np.random.permutation(10000)\n",
    "train_x_gan = train_x_gan[idx]\n",
    "train_y_gan = train_y_gan[idx]\n",
    "# Test\n",
    "idx = np.random.permutation(2500)\n",
    "test_x_gan = test_x_gan[idx]\n",
    "test_y_gan = test_y_gan[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Data normalization between (0,1)\n",
    "\n",
    "# Normalize function\n",
    "def normalize(matrix):\n",
    "    \n",
    "    return (matrix - matrix.min())/(matrix.max() - matrix.min())\n",
    "\n",
    "# MNIST train and test\n",
    "mnist_train_x = normalize(mnist_train_x)\n",
    "mnist_test_x = normalize(mnist_test_x)\n",
    "\n",
    "# Autoencoder train\n",
    "for n,i in enumerate(ae_train_x_new):\n",
    "    ae_train_x_new[n] = normalize(i)\n",
    "# Autoencoder test\n",
    "for n,i in enumerate(ae_test_x_new):\n",
    "    ae_test_x_new[n] = normalize(i)\n",
    "    \n",
    "# DC-GANs train\n",
    "for n,i in enumerate(train_x_gan):\n",
    "    train_x_gan[n] = normalize(i)\n",
    "# DC-GANs test\n",
    "for n,i in enumerate(test_x_gan):\n",
    "    test_x_gan[n] = normalize(i)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "## Creating the dataset:\n",
    "train_X = np.concatenate((mnist_train_x, ae_train_x_new, train_x_gan), axis = 0)\n",
    "train_Y = np.concatenate((mnist_train_y, ae_train_y, train_y_gan), axis = 0)\n",
    "test_X = np.concatenate((mnist_test_x, ae_test_x_new, test_x_gan), axis = 0)\n",
    "test_Y = np.concatenate((mnist_test_y, ae_test_y, test_y_gan), axis = 0)\n",
    "\n",
    "## Final shuffle\n",
    "train_idx = np.random.permutation(60000)\n",
    "train_X = train_X[train_idx]\n",
    "train_Y = train_Y[train_idx]\n",
    "\n",
    "test_idx = np.random.permutation(10000)\n",
    "test_X = test_X[test_idx]\n",
    "test_Y = test_Y[test_idx]\n",
    "\n",
    "\n",
    "## Saving the datasets\n",
    "np.save('data/train_X', train_X)\n",
    "np.save('data/train_Y', train_Y)\n",
    "np.save('data/test_X', test_X)\n",
    "np.save('data/test_Y', test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = np.load()\n",
    "train_Y = np.concatenate((mnist_train_y, ae_train_y, train_y_gan), axis = 0)\n",
    "test_X = np.concatenate((mnist_test_x, ae_test_x_new, test_x_gan), axis = 0)\n",
    "test_Y = np.concatenate((mnist_test_y, ae_test_y, test_y_gan), axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-7fe2deae3317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtest_Y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The shape of the train data set is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The shape of the test data set is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The train dataset was creating by:\n",
    "    - Using 30000 randomly picked instances from the MNIST dataset\n",
    "    - Using 20000 instances generated using an autoencoder \n",
    "    - Using 10000 instances generated using DCGAN\n",
    "    \n",
    "The test dataset was created by:\n",
    "    - Using 5000 randomly picked instances from the MNIST dataset\n",
    "    - Using 2500 instances generated using an autoencoder \n",
    "    - Using 2500 instances generated using DCGAN\n",
    "\n",
    "train_X - a 60000*1*28*28 tensor : features \n",
    "train_y - a 60000*1 tensor : labels\n",
    "\n",
    "test_X - a 10000*1*28*28 tensor : features \n",
    "test_Y - a 10000*1 tensor : labels\n",
    "\"\"\"\n",
    "print(\"The shape of the train data set is {}\".format(train_X.shape))\n",
    "print(\"The shape of the test data set is {}\".format(test_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Loading the datasets\n",
    "# np.load(path)\n",
    "# np.load(\"data/X_train.npy\") <-- example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_X = np.load(\"data/train_test_final/test_X.npy\")\n",
    "test_Y = np.load(\"data/train_test_final/test_Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image id is 5598\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0742bf53ee35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The image id is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The generated image is a {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_Y' is not defined"
     ]
    }
   ],
   "source": [
    "## Playing around with Train dataset \n",
    "idx = np.random.choice(60000,1)[0]\n",
    "plt.imshow(train_X[idx][0])\n",
    "print(\"The image id is {}\".format(idx))\n",
    "print(\"The generated image is a {}\".format(train_Y[idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image id is 2393\n",
      "The generated image is a 3.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1255beef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Playing around with Test dataset \n",
    "idx = np.random.choice(10000,1)[0]\n",
    "plt.imshow(test_X[idx][0])\n",
    "print(\"The image id is {}\".format(idx))\n",
    "print(\"The generated image is a {}\".format(test_Y[idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0.5, 0.5,\n",
       "        0.5, 0.4, 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.8, 0.9, 0.8,\n",
       "        0.8, 0.8, 0.7, 0.4, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.6, 0.8, 0.7, 0.5,\n",
       "        0.4, 0.5, 0.6, 0.7, 0.4, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0.4, 0.1, 0. ,\n",
       "        0. , 0. , 0.1, 0.6, 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.6, 0.7, 0.3, 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.7, 0.8, 0.5, 0.1, 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0.1, 0.8, 0.9, 0.6, 0.2, 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0.5, 0.8, 0.9, 0.7, 0.3, 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0.4,\n",
       "        0.5, 0.7, 0.9, 0.8, 0.7, 0.6, 0.5, 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.3, 0.8,\n",
       "        0.8, 0.8, 0.8, 0.6, 0.5, 0.7, 0.7, 0.1, 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.4, 0.8,\n",
       "        0.8, 0.8, 0.7, 0.4, 0.5, 0.7, 0.9, 0.5, 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.4, 0.6,\n",
       "        0.6, 0.4, 0.4, 0.5, 0.5, 0.6, 0.9, 0.8, 0.2, 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.1, 0.1,\n",
       "        0. , 0. , 0. , 0.1, 0.4, 0.6, 0.9, 0.7, 0.1, 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0.5, 0.7, 0.8, 0.4, 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0.4, 0.7, 0.7, 0.5, 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.2, 0.6, 0.3, 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0.2, 0.6, 0.9, 0.8, 0.4, 0.1, 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0.4, 0.8, 0.8, 0.7, 0.6, 0.5, 0.4, 0.5,\n",
       "        0.5, 0.7, 1. , 0.9, 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.8, 0.8, 0.8, 0.8, 0.7, 0.7,\n",
       "        0.8, 0.8, 0.9, 0.6, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0.5, 0.7, 0.8, 0.9, 0.9,\n",
       "        0.8, 0.9, 0.9, 0.4, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.2, 0.4, 0.6, 0.6,\n",
       "        0.5, 0.5, 0.5, 0.1, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ,\n",
       "        0. , 0. ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = np.around(test_X[idx][0],1).astype(float)\n",
    "temp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STORAGE = np.load('../Numerical Method/data/STORAGE_3.npy')\n",
    "relevant_idx = list()\n",
    "for i in range(len(STORAGE)):\n",
    "    relevant_idx.append(STORAGE[i,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5369"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relevant_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
